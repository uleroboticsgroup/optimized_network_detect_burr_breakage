{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from contour_features import load_image, process_image, cut_section, cut_image, calculate_features, show_process\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2802\n",
    "test_size = 0.2\n",
    "batch_size = 4\n",
    "num_classes = 3\n",
    "\n",
    "input_dir = \"data/images\"\n",
    "target_dir = \"data/mask\"\n",
    "\n",
    "input_shape = (320,320)\n",
    "\n",
    "features = ['dist', 'extent', 'slope', 'pwp_limit', 'pwp_middle']\n",
    "\n",
    "PROCESS_IMAGES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>part</th>\n",
       "      <th>section</th>\n",
       "      <th>min_height</th>\n",
       "      <th>max_height</th>\n",
       "      <th>diff_height</th>\n",
       "      <th>piece_position</th>\n",
       "      <th>class</th>\n",
       "      <th>image_id</th>\n",
       "      <th>set</th>\n",
       "      <th>path</th>\n",
       "      <th>category</th>\n",
       "      <th>binary_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>P01_001_0</td>\n",
       "      <td>P01</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>200</td>\n",
       "      <td>19</td>\n",
       "      <td>Down</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>data/images/P01_001_0.jpg</td>\n",
       "      <td>NB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>P01_001_1</td>\n",
       "      <td>P01</td>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>208</td>\n",
       "      <td>10</td>\n",
       "      <td>Down</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>data/images/P01_001_1.jpg</td>\n",
       "      <td>NB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>P01_001_2</td>\n",
       "      <td>P01</td>\n",
       "      <td>2</td>\n",
       "      <td>204</td>\n",
       "      <td>214</td>\n",
       "      <td>10</td>\n",
       "      <td>Down</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>data/images/P01_001_2.jpg</td>\n",
       "      <td>NB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>P01_001_3</td>\n",
       "      <td>P01</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>212</td>\n",
       "      <td>12</td>\n",
       "      <td>Down</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Train</td>\n",
       "      <td>data/images/P01_001_3.jpg</td>\n",
       "      <td>NB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>P01_002_0</td>\n",
       "      <td>P01</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>238</td>\n",
       "      <td>6</td>\n",
       "      <td>Down</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Train</td>\n",
       "      <td>data/images/P01_002_0.jpg</td>\n",
       "      <td>NB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 image_name part  section  min_height  max_height  diff_height  \\\n",
       "0           0  P01_001_0  P01        0         181         200           19   \n",
       "1           1  P01_001_1  P01        1         198         208           10   \n",
       "2           2  P01_001_2  P01        2         204         214           10   \n",
       "3           3  P01_001_3  P01        3         200         212           12   \n",
       "4           4  P01_002_0  P01        0         232         238            6   \n",
       "\n",
       "  piece_position  class  image_id    set                       path category  \\\n",
       "0           Down      2         1  Train  data/images/P01_001_0.jpg       NB   \n",
       "1           Down      1         1  Train  data/images/P01_001_1.jpg       NB   \n",
       "2           Down      1         1  Train  data/images/P01_001_2.jpg       NB   \n",
       "3           Down      1         1  Train  data/images/P01_001_3.jpg       NB   \n",
       "4           Down      1         2  Train  data/images/P01_002_0.jpg       NB   \n",
       "\n",
       "   binary_class  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/dataset_train_test.csv') \n",
    "df['path'] = input_dir+'/'+df['image_name']+'.jpg'\n",
    "df['category'] = np.where(df['class']==1, 'NB', np.where(df['class']==2, 'NB', 'B'))\n",
    "df['binary_class'] = np.where(df['class']==1, 0, np.where(df['class']==2, 0, 1))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROCESS_IMAGES:\n",
    "    data = pd.DataFrame(columns=['img_name', 'category','set']+features)\n",
    "    for _, row in df.iterrows():\n",
    "        print(row['path'])\n",
    "        image = load_image(row['path'])\n",
    "        img_process = process_image(image)\n",
    "        data_vector =  cut_section(img_process[-1])\n",
    "        if \"dist\" in data_vector:  \n",
    "                img_cut = cut_image(img_process[0],data_vector['y1'],data_vector['y2'])\n",
    "                if img_cut.shape[0]>10:\n",
    "                    img_process_cut = process_image(img_cut, clahe_tile = (5,5), kernel_size=(17,39))            \n",
    "                    data_vector_cut =  cut_section(img_process_cut[-1], True, True)\n",
    "\n",
    "                    if \"contour_line\" in data_vector_cut:\n",
    "                        calculate_features(img_process_cut[-1], data_vector_cut, True)  \n",
    "                        if \"extent\" in data_vector_cut:\n",
    "                            info = {'img_name': row['image_name'],'category': row['class'], 'binary_class': row['binary_class'], 'set': row['set']}\n",
    "                            for feature in features:\n",
    "                                info[feature] = data_vector_cut[feature]\n",
    "                            data = data.append(info, ignore_index=True)\n",
    "    data.to_csv('results/traditional_data_complete.csv', index=False, sep=';', decimal=\".\")\n",
    "    data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('results/traditional_data_complete.csv', delimiter=';', decimal=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[data['set']=='Train']\n",
    "data_test = data[data['set']=='Test']\n",
    "\n",
    "X_train = data_train[features]\n",
    "y_train = data_train[['binary_class']].values.ravel()\n",
    "\n",
    "X_test = data_test[features]\n",
    "y_test = data_test[['binary_class']].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       661\n",
      "         1.0     1.0000    1.0000    1.0000       185\n",
      "\n",
      "    accuracy                         1.0000       846\n",
      "   macro avg     1.0000    1.0000    1.0000       846\n",
      "weighted avg     1.0000    1.0000    1.0000       846\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9162    0.9053    0.9107       169\n",
      "         1.0     0.6522    0.6818    0.6667        44\n",
      "\n",
      "    accuracy                         0.8592       213\n",
      "   macro avg     0.7842    0.7936    0.7887       213\n",
      "weighted avg     0.8616    0.8592    0.8603       213\n",
      "\n",
      "0.4052236080169678\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=seed,n_jobs=-1, criterion = 'entropy', max_depth= 14, n_estimators=95)\n",
    "start = time()\n",
    "model = model.fit(X_train, y_train)\n",
    "y_predict_train = model.predict(X_train)\n",
    "print(classification_report(y_train,y_predict_train, digits=4))\n",
    "y_predict= model.predict(X_test)\n",
    "print(classification_report(y_test,y_predict, digits=4))\n",
    "train_time = time()-start\n",
    "print(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensivity 0.6818181818181818 \tSpecificity 0.9053254437869822\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test,y_predict).ravel()\n",
    "\n",
    "sensivity = tp /(tp+fn)\n",
    "specificity = tn /(tn+fp)\n",
    "\n",
    "print('Sensivity', sensivity, '\\tSpecificity', specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8891596794128418 seconds\n",
      "889.1596794128418 milliseconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\virgi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    }
   ],
   "source": [
    "image = load_image(input_dir+'/'+data.loc[0].img_name+'.jpg')\n",
    "\n",
    "times = []\n",
    "for _ in range(15):\n",
    "    start = time()\n",
    "    img_process = process_image(image)\n",
    "    data_vector =  cut_section(img_process[-1])\n",
    "    img_cut = cut_image(img_process[0],data_vector['y1'],data_vector['y2'])\n",
    "    img_process_cut = process_image(img_cut, clahe_tile = (5,5), kernel_size=(17,39))            \n",
    "    data_vector_cut =  cut_section(img_process_cut[-1], True, True)\n",
    "    calculate_features(img_process_cut[-1], data_vector_cut, True)  \n",
    "    info = []\n",
    "    for feature in features:\n",
    "        info.append(data_vector_cut[feature])\n",
    "    X_input = np.expand_dims(info, axis=0)\n",
    "\n",
    "    a = model.predict(X_input)\n",
    "    evaluation_time = time()-start\n",
    "    times.append(evaluation_time)\n",
    "mean_time = np.median(np.array(times))\n",
    "print(mean_time,'seconds')\n",
    "print(mean_time*1000,'milliseconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
